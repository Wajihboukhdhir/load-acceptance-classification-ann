{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Customer Churn Prediction: Predicting whether churn or not (Binary classification) using artificial neural network (ANN)\n",
    "-we have also implemented different techniques for handling data imbalance (Undersampling,Oversampling,SMOTE,Ensemble method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"C:/Users/Wajih/Desktop/Projects Wajih/Customer Churn Prediction ANN/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need CustomerID as it is not useful for building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 'columns' : specifies that you are dropping a column, not a row (0 OR 'index' for rows and 1 OR 'columns' for columns)\n",
    "# Since inplace=True, the operation happens directly on df without needing to assign the result to a new variable (if false)\n",
    "\n",
    "df.drop('customerID',axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to convert TotalCharges column to be having the same type of MonthlyCharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nulls = df['TotalCharges'].isnull().sum()\n",
    "num_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont have null values for that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "488   Female              0     Yes        Yes       0           No   \n",
       "753     Male              0      No        Yes       0          Yes   \n",
       "936   Female              0     Yes        Yes       0          Yes   \n",
       "1082    Male              0     Yes        Yes       0          Yes   \n",
       "1340  Female              0     Yes        Yes       0           No   \n",
       "3331    Male              0     Yes        Yes       0          Yes   \n",
       "3826    Male              0     Yes        Yes       0          Yes   \n",
       "4380  Female              0     Yes        Yes       0          Yes   \n",
       "5218    Male              0     Yes        Yes       0          Yes   \n",
       "6670  Female              0     Yes        Yes       0          Yes   \n",
       "6754    Male              0      No        Yes       0          Yes   \n",
       "\n",
       "         MultipleLines InternetService       OnlineSecurity  \\\n",
       "488   No phone service             DSL                  Yes   \n",
       "753                 No              No  No internet service   \n",
       "936                 No             DSL                  Yes   \n",
       "1082               Yes              No  No internet service   \n",
       "1340  No phone service             DSL                  Yes   \n",
       "3331                No              No  No internet service   \n",
       "3826               Yes              No  No internet service   \n",
       "4380                No              No  No internet service   \n",
       "5218                No              No  No internet service   \n",
       "6670               Yes             DSL                   No   \n",
       "6754               Yes             DSL                  Yes   \n",
       "\n",
       "             OnlineBackup     DeviceProtection          TechSupport  \\\n",
       "488                    No                  Yes                  Yes   \n",
       "753   No internet service  No internet service  No internet service   \n",
       "936                   Yes                  Yes                   No   \n",
       "1082  No internet service  No internet service  No internet service   \n",
       "1340                  Yes                  Yes                  Yes   \n",
       "3331  No internet service  No internet service  No internet service   \n",
       "3826  No internet service  No internet service  No internet service   \n",
       "4380  No internet service  No internet service  No internet service   \n",
       "5218  No internet service  No internet service  No internet service   \n",
       "6670                  Yes                  Yes                  Yes   \n",
       "6754                  Yes                   No                  Yes   \n",
       "\n",
       "              StreamingTV      StreamingMovies  Contract PaperlessBilling  \\\n",
       "488                   Yes                   No  Two year              Yes   \n",
       "753   No internet service  No internet service  Two year               No   \n",
       "936                   Yes                  Yes  Two year               No   \n",
       "1082  No internet service  No internet service  Two year               No   \n",
       "1340                  Yes                   No  Two year               No   \n",
       "3331  No internet service  No internet service  Two year               No   \n",
       "3826  No internet service  No internet service  Two year               No   \n",
       "4380  No internet service  No internet service  Two year               No   \n",
       "5218  No internet service  No internet service  One year              Yes   \n",
       "6670                  Yes                   No  Two year               No   \n",
       "6754                   No                   No  Two year              Yes   \n",
       "\n",
       "                  PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
       "488   Bank transfer (automatic)           52.55                 No  \n",
       "753                Mailed check           20.25                 No  \n",
       "936                Mailed check           80.85                 No  \n",
       "1082               Mailed check           25.75                 No  \n",
       "1340    Credit card (automatic)           56.05                 No  \n",
       "3331               Mailed check           19.85                 No  \n",
       "3826               Mailed check           25.35                 No  \n",
       "4380               Mailed check           20.00                 No  \n",
       "5218               Mailed check           19.70                 No  \n",
       "6670               Mailed check           73.35                 No  \n",
       "6754  Bank transfer (automatic)           61.90                 No  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# errors = 'coerce' means if there is an error in conversion, we return NaN\n",
    "# pd.to_numeric converts the values of the TotalCharges column to numeric data\n",
    "# isnull() return a boolean series of True and False,\n",
    "df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 11 rown with that column is blank, we can remove them since they are not so many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataframe:  (7043, 20)\n",
      "Updated Dataframe:  (7032, 20)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[df.TotalCharges != ' ']\n",
    "print(\"Initial Dataframe: \",df.shape)\n",
    "print(\"Updated Dataframe: \",df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\2999043133.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.TotalCharges= pd.to_numeric(df1.TotalCharges)\n"
     ]
    }
   ],
   "source": [
    "# we convert the totalCharges column to numeric\n",
    "df1.TotalCharges= pd.to_numeric(df1.TotalCharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Data visualisation for some variables that are considered important for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163\n",
      "0        1\n",
      "1       34\n",
      "3       45\n",
      "6       22\n",
      "7       10\n",
      "        ..\n",
      "7037    72\n",
      "7038    24\n",
      "7039    72\n",
      "7040    11\n",
      "7042    66\n",
      "Name: tenure, Length: 5163, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "tenure_churn_no = df1[df1[\"Churn\"]==\"No\"].tenure\n",
    "print(len(tenure_churn_no))\n",
    "print(tenure_churn_no)\n",
    "print(type(tenure_churn_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869\n"
     ]
    }
   ],
   "source": [
    "tenure_churn_yes = df1[df1[\"Churn\"]==\"Yes\"].tenure\n",
    "print(len(tenure_churn_yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15db53bc980>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([tenure_churn_yes,tenure_churn_no],color=['green','red'],label=['Churn=Yes','Churn=No'])\n",
    "plt.xlabel(\"tenure\")\n",
    "plt.ylabel(\"Number Of Customers\")\n",
    "plt.title(\"Customer Churn Prediction Visualization: Tenure\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15db543e930>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MonthlyCharges_churn_no = df1[df1[\"Churn\"]==\"No\"].MonthlyCharges\n",
    "\n",
    "MonthlyCharges_churn_yes = df1[df1[\"Churn\"]==\"Yes\"].MonthlyCharges\n",
    "\n",
    "\n",
    "plt.hist([MonthlyCharges_churn_yes,MonthlyCharges_churn_no],color=['green','red'],label=['Churn=Yes','Churn=No'])\n",
    "plt.xlabel(\"Monthly Charges\")\n",
    "plt.ylabel(\"Count Of Customers\")\n",
    "plt.title(\"Customer Churn Prediction Visualization: Monthly Charges\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to print the unique values for only textual(categorical) columns in the dataframe\n",
    "def LabelObjectColumns(df1):\n",
    "    for col in df1:\n",
    "        #Checks if the data type of the column (df1[col].dtypes) is 'object', which in pandas typically represents text or mixed data.\n",
    "        if df1[col].dtypes=='object':\n",
    "            print(col,df1[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender ['Female' 'Male']\n",
      "Partner ['Yes' 'No']\n",
      "Dependents ['No' 'Yes']\n",
      "PhoneService ['No' 'Yes']\n",
      "MultipleLines ['No phone service' 'No' 'Yes']\n",
      "InternetService ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection ['No' 'Yes' 'No internet service']\n",
      "TechSupport ['No' 'Yes' 'No internet service']\n",
      "StreamingTV ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies ['No' 'Yes' 'No internet service']\n",
      "Contract ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling ['Yes' 'No']\n",
      "PaymentMethod ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "LabelObjectColumns(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\2045096646.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No internet service','No',inplace=True)\n",
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\2045096646.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No phone service','No',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df1.replace('No internet service','No',inplace=True)\n",
    "df1.replace('No phone service','No',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender ['Female' 'Male']\n",
      "Partner ['Yes' 'No']\n",
      "Dependents ['No' 'Yes']\n",
      "PhoneService ['No' 'Yes']\n",
      "MultipleLines ['No' 'Yes']\n",
      "InternetService ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity ['No' 'Yes']\n",
      "OnlineBackup ['Yes' 'No']\n",
      "DeviceProtection ['No' 'Yes']\n",
      "TechSupport ['No' 'Yes']\n",
      "StreamingTV ['No' 'Yes']\n",
      "StreamingMovies ['No' 'Yes']\n",
      "Contract ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling ['Yes' 'No']\n",
      "PaymentMethod ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "LabelObjectColumns(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\1648037665.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1[col].replace({'Yes': 1,'No': 0},inplace=True)\n",
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\1648037665.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1[col].replace({'Yes': 1,'No': 0},inplace=True)\n",
      "C:\\Users\\Wajih\\AppData\\Local\\Temp\\ipykernel_5536\\1648037665.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[col].replace({'Yes': 1,'No': 0},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n",
    "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n",
    "for col in yes_no_columns:\n",
    "    df1[col].replace({'Yes': 1,'No': 0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender ['Female' 'Male']\n",
      "InternetService ['DSL' 'Fiber optic' 'No']\n",
      "Contract ['Month-to-month' 'One year' 'Two year']\n",
      "PaymentMethod ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n"
     ]
    }
   ],
   "source": [
    "LabelObjectColumns(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'].replace({'Female':1,'Male':0},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternetService ['DSL' 'Fiber optic' 'No']\n",
      "Contract ['Month-to-month' 'One year' 'Two year']\n",
      "PaymentMethod ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n"
     ]
    }
   ],
   "source": [
    "LabelObjectColumns(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding for our categorical variables: a column that will be added in dataframe for each unique value of category every categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# this will create for each unique value a new column that is a dummy variable (dtype=int as we want to show 0 or 1;if not written, it will be boolean)\n",
    "df2 = pd.get_dummies(data=df1,dtype=int, columns=['InternetService','Contract','PaymentMethod'])\n",
    "print(LabelObjectColumns(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our variables now are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                                       int64\n",
       "SeniorCitizen                                int64\n",
       "Partner                                      int64\n",
       "Dependents                                   int64\n",
       "tenure                                       int64\n",
       "PhoneService                                 int64\n",
       "MultipleLines                                int64\n",
       "OnlineSecurity                               int64\n",
       "OnlineBackup                                 int64\n",
       "DeviceProtection                             int64\n",
       "TechSupport                                  int64\n",
       "StreamingTV                                  int64\n",
       "StreamingMovies                              int64\n",
       "PaperlessBilling                             int64\n",
       "MonthlyCharges                             float64\n",
       "TotalCharges                               float64\n",
       "Churn                                        int64\n",
       "InternetService_DSL                          int32\n",
       "InternetService_Fiber optic                  int32\n",
       "InternetService_No                           int32\n",
       "Contract_Month-to-month                      int32\n",
       "Contract_One year                            int32\n",
       "Contract_Two year                            int32\n",
       "PaymentMethod_Bank transfer (automatic)      int32\n",
       "PaymentMethod_Credit card (automatic)        int32\n",
       "PaymentMethod_Electronic check               int32\n",
       "PaymentMethod_Mailed check                   int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
       "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
       "       'PaperlessBilling', 'MonthlyCharges', 'TotalCharges', 'Churn',\n",
       "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
       "       'InternetService_No', 'Contract_Month-to-month', 'Contract_One year',\n",
       "       'Contract_Two year', 'PaymentMethod_Bank transfer (automatic)',\n",
       "       'PaymentMethod_Credit card (automatic)',\n",
       "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 27)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are variables that are binary and variables that have a higher range, we have to do scaling for our variables\n",
    "# scaling is important before doing an deep learning\n",
    "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
    "# imports the MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Creates an instance of the MinMaxScaler class named scaler.\n",
    "scaler = MinMaxScaler()\n",
    "# fit_transform: 1 -fit creates the min and max that will be used as scaling parameters / 2- transform scales the data based on the parameters\n",
    "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "1097       0              0        1           1  0.338028             1   \n",
       "2331       1              0        1           0  0.338028             1   \n",
       "3335       0              0        0           0  0.154930             1   \n",
       "5682       1              0        1           0  0.000000             0   \n",
       "4277       1              0        0           0  0.070423             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "1097              0               0             0                 0  ...   \n",
       "2331              1               0             0                 0  ...   \n",
       "3335              1               0             0                 0  ...   \n",
       "5682              0               0             0                 0  ...   \n",
       "4277              0               0             0                 0  ...   \n",
       "\n",
       "      InternetService_DSL  InternetService_Fiber optic  InternetService_No  \\\n",
       "1097                    0                            1                   0   \n",
       "2331                    0                            0                   1   \n",
       "3335                    0                            0                   1   \n",
       "5682                    1                            0                   0   \n",
       "4277                    0                            0                   1   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "1097                        0                  1                  0   \n",
       "2331                        0                  1                  0   \n",
       "3335                        1                  0                  0   \n",
       "5682                        1                  0                  0   \n",
       "4277                        1                  0                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "1097                                        0   \n",
       "2331                                        0   \n",
       "3335                                        0   \n",
       "5682                                        0   \n",
       "4277                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "1097                                      0                               1   \n",
       "2331                                      0                               0   \n",
       "3335                                      0                               1   \n",
       "5682                                      0                               1   \n",
       "4277                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "1097                           0  \n",
       "2331                           1  \n",
       "3335                           0  \n",
       "5682                           0  \n",
       "4277                           1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the training and test datasets\n",
    "X = df2.drop('Churn',axis='columns')\n",
    "y = df2['Churn']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5612 - loss: 0.6467\n",
      "Epoch 2/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4250\n",
      "Epoch 3/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4130\n",
      "Epoch 4/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7928 - loss: 0.4179\n",
      "Epoch 5/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8067 - loss: 0.4022\n",
      "Epoch 6/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4012\n",
      "Epoch 7/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8018 - loss: 0.4148\n",
      "Epoch 8/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4009\n",
      "Epoch 9/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.3835\n",
      "Epoch 10/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4066\n",
      "Epoch 11/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8105 - loss: 0.4052\n",
      "Epoch 12/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8254 - loss: 0.3970\n",
      "Epoch 13/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.3912\n",
      "Epoch 14/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.3957\n",
      "Epoch 15/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3963\n",
      "Epoch 16/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.3922\n",
      "Epoch 17/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.3937\n",
      "Epoch 18/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.3846\n",
      "Epoch 19/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.3993\n",
      "Epoch 20/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.4048\n",
      "Epoch 21/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3808\n",
      "Epoch 22/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3926\n",
      "Epoch 23/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.3958\n",
      "Epoch 24/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3907\n",
      "Epoch 25/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.3810\n",
      "Epoch 26/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.3905\n",
      "Epoch 27/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3824\n",
      "Epoch 28/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8148 - loss: 0.3908\n",
      "Epoch 29/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3655\n",
      "Epoch 30/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3815\n",
      "Epoch 31/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.3875\n",
      "Epoch 32/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3755\n",
      "Epoch 33/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3825\n",
      "Epoch 34/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.3750\n",
      "Epoch 35/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3876\n",
      "Epoch 36/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.3790\n",
      "Epoch 37/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.3740\n",
      "Epoch 38/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3730\n",
      "Epoch 39/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.3805\n",
      "Epoch 40/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3676\n",
      "Epoch 41/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.3693\n",
      "Epoch 42/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.3751\n",
      "Epoch 43/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.3626\n",
      "Epoch 44/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3674\n",
      "Epoch 45/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.3720\n",
      "Epoch 46/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3627\n",
      "Epoch 47/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.3726\n",
      "Epoch 48/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.3685\n",
      "Epoch 49/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.3723\n",
      "Epoch 50/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.3688\n",
      "Epoch 51/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.3606\n",
      "Epoch 52/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.3688\n",
      "Epoch 53/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.3709\n",
      "Epoch 54/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8271 - loss: 0.3695\n",
      "Epoch 55/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3680\n",
      "Epoch 56/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.3701\n",
      "Epoch 57/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.3612\n",
      "Epoch 58/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.3563\n",
      "Epoch 59/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.3700\n",
      "Epoch 60/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.3738\n",
      "Epoch 61/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3600\n",
      "Epoch 62/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.3486\n",
      "Epoch 63/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3526\n",
      "Epoch 64/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.3629\n",
      "Epoch 65/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8248 - loss: 0.3729\n",
      "Epoch 66/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3621\n",
      "Epoch 67/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.3600\n",
      "Epoch 68/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3543\n",
      "Epoch 69/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3563\n",
      "Epoch 70/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.3517\n",
      "Epoch 71/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.3434\n",
      "Epoch 72/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8412 - loss: 0.3509\n",
      "Epoch 73/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.3547\n",
      "Epoch 74/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3456\n",
      "Epoch 75/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3580\n",
      "Epoch 76/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.3545\n",
      "Epoch 77/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3540\n",
      "Epoch 78/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3466\n",
      "Epoch 79/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3500\n",
      "Epoch 80/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3507\n",
      "Epoch 81/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8259 - loss: 0.3616\n",
      "Epoch 82/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3579\n",
      "Epoch 83/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3450\n",
      "Epoch 84/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8411 - loss: 0.3501\n",
      "Epoch 85/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3309\n",
      "Epoch 86/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8278 - loss: 0.3653\n",
      "Epoch 87/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3420\n",
      "Epoch 88/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3447\n",
      "Epoch 89/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.3506\n",
      "Epoch 90/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3588\n",
      "Epoch 91/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3642\n",
      "Epoch 92/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3344\n",
      "Epoch 93/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.3421\n",
      "Epoch 94/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.3532\n",
      "Epoch 95/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3333\n",
      "Epoch 96/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3502\n",
      "Epoch 97/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.3545\n",
      "Epoch 98/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.3338\n",
      "Epoch 99/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3385\n",
      "Epoch 100/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8419 - loss: 0.3434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15dc9513590>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# keras.Sequential: Creates a sequential model where layers are stacked one after the other.\n",
    "# keras.layers.Dense: Defines a fully connected (dense) layer\n",
    "# input_shape=(26,): Specifies the input shape (a vector of size 26)\n",
    "# activation='relu': Applies the ReLU (Rectified Linear Unit) activation function, which outputs max(0, x): most used in hidden layers\n",
    "# second layer dense layer with 15 neurons and the ReLU activation function\n",
    "# activation='sigmoid': Outputs values between 0 and 1, making it suitable for binary classification.\n",
    "# output layer with only one neuron as we have 1 value for output (between 0 and one)\n",
    "\n",
    "# IMPORTANT: in Keras, the input layer is often implicit and integrated into the first layer when you define the input_shape parameter\n",
    "# If your dataset has 26 features, the input shape is the same (the other \"26\" is the number of neurons in the first layer(which can be different that 26)).\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(26, input_shape=(26,), activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# model.compile: connects the model to the specified optimizer,loss function and metrics and prepares how the model will calculate loss and update weight during the fitting part\n",
    "\n",
    "# Adam optimizer, which adjusts learning rates dynamically during training\n",
    "# loss='binary_crossentropy': loss function for binary classification problems.\n",
    "# accuracy: tracks accuraty as a metric for training and evaluation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.4743\n",
      "Test Loss: 0.482907235622406, Test Accuracy: 0.7675906419754028\n"
     ]
    }
   ],
   "source": [
    "# first value: loss ; second value: accuracy\n",
    "# The model makes predictions on the test data (X_test) and compares them with the true labels (y_test)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# predicting using the test data and choosing as 1 values higher than threshold (in my case 0.5)\n",
    "yp = model.predict(X_test)\n",
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       999\n",
      "           1       0.62      0.50      0.56       408\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.72      0.69      0.70      1407\n",
      "weighted avg       0.76      0.77      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxEAAAJaCAYAAABQj8p9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7TklEQVR4nO3de5hWZb0//vdwGjk4ICozUKGkJmCkBgXTyUoEFUs3WNu2GaY7dwSU4JH9VVMsR223TSulg4p91TxUug1LQzyVjieKtpqipoUlAyoCQT+Hwzy/P/oyPZPowzKYAX29vNZ1OWvdz1qfma5rmo/vdd93ValUKgUAAGATderoAgAAgG2LJgIAAChEEwEAABSiiQAAAArRRAAAAIVoIgAAgEI0EQAAQCGaCAAAoBBNBAAAUEiXji5gS1j7wtMdXQLAZtV9wAc7ugSAzWrdmj93dAmvqj3/luy609vb7VmbkyQCAAAo5A2ZRAAAwOvWsr6jK9jqSSIAAIBCJBEAAFCu1NLRFWz1JBEAAEAhkggAACjXIomoRBIBAAAUIokAAIAyJXMiKpJEAAAAhUgiAACgnDkRFUkiAACAQiQRAABQzpyIiiQRAABAIZIIAAAo17K+oyvY6kkiAACAQjQRAABAIV5nAgCAciZWVySJAAAACpFEAABAOZvNVSSJAAAACpFEAABAmZI5ERVJIgAAgEIkEQAAUM6ciIokEQAAQCGSCAAAKGdOREWSCAAAoBBJBAAAlGtZ39EVbPUkEQAAQCGSCAAAKGdOREWSCAAAoBBJBAAAlLNPREWSCAAAoBBJBAAAlDMnoiJJBAAAUIgmAgAAKMTrTAAAUM7E6ookEQAAQCGSCAAAKFMqre/oErZ6kggAAKAQSQQAAJSzxGtFkggAAKAQSQQAAJSzOlNFkggAAKAQSQQAAJQzJ6IiSQQAAFCIJAIAAMq12CeiEkkEAABQiCQCAADKmRNRkSQCAAAoRBMBAADlWlra7yhg/fr1Of300zNo0KB07949u+22W84+++yUSqXWMaVSKWeccUb69++f7t27Z/To0XnyySfb3GfZsmU58sgjU1NTkz59+uTYY4/NqlWrCtWiiQAAgG3Aeeedl0suuSTf+ta38thjj+W8887L+eefn29+85utY84///xcdNFFmTVrVu6///707NkzY8eOzcsvv9w65sgjj8yjjz6auXPnZs6cObn77rtz3HHHFaqlqlTeurxBrH3h6Y4uAWCz6j7ggx1dAsBmtW7Nnzu6hFf1cuMP2+1Z29V/apPHHnLIIamtrc2ll17aem7ChAnp3r17rrzyypRKpQwYMCAnnHBCTjzxxCTJihUrUltbm9mzZ+eII47IY489lqFDh+bBBx/MiBEjkiS33HJLDj744PzpT3/KgAEDNqkWSQQAAHSQ5ubmrFy5ss3R3Ny80bHve9/7Mm/evDzxxBNJkt/+9rf51a9+lYMOOihJ8swzz6SpqSmjR49u/Uzv3r0zcuTINDY2JkkaGxvTp0+f1gYiSUaPHp1OnTrl/vvv3+S6NREAAFCuHedENDQ0pHfv3m2OhoaGjZZ16qmn5ogjjsjgwYPTtWvX7Lvvvjn++ONz5JFHJkmampqSJLW1tW0+V1tb23qtqakp/fr1a3O9S5cu6du3b+uYTWGJVwAA6CAzZszI9OnT25yrrq7e6NjrrrsuV111Va6++urstddeWbBgQY4//vgMGDAgEydObI9yW2kiAACgg1RXV79q0/CPTjrppNY0IkmGDRuWP/7xj2loaMjEiRNTV1eXJFmyZEn69+/f+rklS5Zkn332SZLU1dVl6dKlbe67bt26LFu2rPXzm8LrTAAAUG4rXeL1r3/9azp1avvne+fOndPy/+4zaNCg1NXVZd68ea3XV65cmfvvvz/19fVJkvr6+ixfvjzz589vHXP77benpaUlI0eO3ORaJBEAALAN+NjHPpavfvWrGThwYPbaa6/85je/yX//93/nmGOOSZJUVVXl+OOPz1e+8pXsscceGTRoUE4//fQMGDAghx12WJJkyJAhOfDAA/O5z30us2bNytq1azNlypQcccQRm7wyU6KJAACANkql9R1dwkZ985vfzOmnn54vfOELWbp0aQYMGJD/+I//yBlnnNE65uSTT87q1atz3HHHZfny5fnABz6QW265Jdttt13rmKuuuipTpkzJ/vvvn06dOmXChAm56KKLCtVinwiAbYB9IoA3mq15n4j/7+7Z7fas7h86ut2etTlJIgAAoFzBuQpvRiZWAwAAhUgiAACgXEkSUYkkAgAAKEQSAQAA5cyJqEgSAQAAFCKJAACAcuZEVCSJAAAACpFEAABAOXMiKpJEAAAAhUgiAACgnDkRFUkiAACAQiQRAABQzpyIiiQRAABAIZoIAACgEK8zAQBAOa8zVSSJAAAACpFEAABAOUu8ViSJAAAACpFEAABAOXMiKpJEAAAAhUgiAACgnDkRFUkiAACAQiQRAABQzpyIiiQRAABAIZIIAAAoZ05ERZIIAACgEEkEAACUMyeiIkkEAABQiCQCAADKSSIqkkQAAACFSCIAAKBcqdTRFWz1JBEAAEAhkggAAChnTkRFkggAAKAQTQQAAFCI15kAAKCc15kqkkQAAACFSCIAAKBcSRJRiSQCAAAoRBIBAADlzImoSBIBAAAUIokAAIBypVJHV7DVk0QAAACFSCIAAKCcOREVSSIAAIBCJBEAAFBOElGRJAIAAChEEgEAAOXsWF2RJAIAAChEEgEAAGVKLfaJqEQSAQAAFCKJAACAclZnqkgSAQAAFKKJAAAACvE6EwAAlLPEa0WSCAAAoBBJBAAAlLPEa0WSCAAAoBBJBAAAlLPEa0WSCAAA2AbsuuuuqaqqesUxefLkJMnLL7+cyZMnZ8cdd0yvXr0yYcKELFmypM09Fi1alHHjxqVHjx7p169fTjrppKxbt65wLZIIAAAot5UmEQ8++GDWr1/f+vUjjzySAw44IJ/4xCeSJNOmTcvNN9+c66+/Pr17986UKVMyfvz43HPPPUmS9evXZ9y4camrq8u9996bxYsX5zOf+Uy6du2ac845p1AtVaVS6Q03c2TtC093dAkAm1X3AR/s6BIANqt1a/7c0SW8qr9e+Pl2e1aPL8163Z89/vjjM2fOnDz55JNZuXJldt5551x99dU5/PDDkySPP/54hgwZksbGxowaNSo///nPc8ghh+S5555LbW1tkmTWrFk55ZRT8vzzz6dbt26b/GyvMwEAQLlSqf2O12nNmjW58sorc8wxx6Sqqirz58/P2rVrM3r06NYxgwcPzsCBA9PY2JgkaWxszLBhw1obiCQZO3ZsVq5cmUcffbTQ873OBAAAHaS5uTnNzc1tzlVXV6e6uvo1P3fjjTdm+fLlOfroo5MkTU1N6datW/r06dNmXG1tbZqamlrHlDcQG65vuFaEJAIAAMq1tLTb0dDQkN69e7c5GhoaKpZ46aWX5qCDDsqAAQPa4QfySpIIAADoIDNmzMj06dPbnKuUQvzxj3/Mbbfdlp/85Cet5+rq6rJmzZosX768TRqxZMmS1NXVtY554IEH2txrw+pNG8ZsKkkEAACUaym121FdXZ2ampo2R6Um4vLLL0+/fv0ybty41nPDhw9P165dM2/evNZzCxcuzKJFi1JfX58kqa+vz8MPP5ylS5e2jpk7d25qamoydOjQQj8iSQSUWb9+fS6+9KrM+cXteeHFl7LzTn1z2MEH5D+O/lSqqqqSJO98/0Eb/ez0LxybY448vPXru+59ILMuvzpPPPVMqqu7ZcQ+w3LRuWe0y/cBUO6DHxiZE06YlHfvOywDBtRl/OHH5Kabbk2SdOnSJWfPPDkHHvjRvH3QLlmxYmXm3f6r/Of/OSeLF/99ffkbfnJ59n7XXunXb8e89NKKzLv9V5nxn19tMwbY8lpaWnL55Zdn4sSJ6dLl73/K9+7dO8cee2ymT5+evn37pqamJlOnTk19fX1GjRqVJBkzZkyGDh2ao446Kueff36amppy2mmnZfLkyRUbl3+kiYAyl155fa698eZ89bQTsvugXfLo40/ktK9ekF69eubTnzg0SXLnTVe1+cwv73soZzR8Iwd8+P2t5+be8at8+bwL86X/ODojh++d9evX58mn/9iu3wvABj179sj//u/vcvnsa/Lj6y9tc61Hj+7Zd59h+eo5F+Z///d32aFP71zw32flhp9cnlH1B7eOu/POe3Puud/M4qYlecuA/jn/vNNz3TXfzQf3O7S9vx3Y8kpb5z4RSXLbbbdl0aJFOeaYY15x7YILLkinTp0yYcKENDc3Z+zYsbn44otbr3fu3Dlz5szJpEmTUl9fn549e2bixImZOXNm4TrsEwFlvnDSl7Nj3z45e8a01nPH/+dXUl3dLed9+eSNfuaLp87M6r/+NZdedG6SZN269Rl7+MR84dijMuFjY9ulbt747BPB5rJuzZ/bJBEbM2L43rmv8WcZtNt78uyzz210zCGHHJCf/Oiy9Og16HXtdgtb9T4RX3vlH+hbSo+TLmu3Z21OHZpEvPDCC7nsssvS2NjYuqxUXV1d3ve+9+Xoo4/Ozjvv3JHl8Sa0zzuH5Ec3/Tx/WPSn7DrwrXn8yafz6/99NCdP/dxGx7+w7KXcfe8D+eppJ7See+yJp7Lk+RfTqVNVDj96cl5Y9lIG77FbTph8bPZ4+67t9J0AvH69e9ekpaUly5ev3Oj1HXbok3/71Pg0Nj6kgeCNqeUN99/YN7sOayIefPDBjB07Nj169Mjo0aPzjne8I8nfZohfdNFFOffcc3PrrbdmxIgRr3mfja2t26m5ufB7XZAk/37UJ7P6r3/Nx/7tuHTu1CnrW1ryxeMm5pCxH93o+Jt+flt69Oie0fv9/VWmZ59bnCS5+NKrcvLUz2VA/9pccc1P8tkpp+Tma76f3jXbt8v3AvB6VFdX55xz/jPXXHtj/vKXVW2uNZzzn/nCpM+mZ88eue+++fn4YRM7qEqgo3XY6kxTp07NJz7xiTz77LOZPXt2zjvvvJx33nmZPXt2Fi1alMMPPzxTp06teJ+Nra173oWvf/tw3txuuf3uzPnFHTnvzJNz3eXfzFdPOyGzf/jj/M/P5m50/A1zfpFDxnwk1dV/3ya+9P/+68VxE/81B3zkA9lr8B75yn9OS1VVcuvtv2yX7wPg9ejSpUuu+eGsVFVVZfKUGa+4/l9fvyQj3js2Bx50RNavX5/Zl13YAVXClldqaWm3Y1vVYUnEb3/728yePbt1xZtyVVVVmTZtWvbdd9+K99nY2rqd/rL1vmPH1u3r3740//7pT+bg0R9Okrxjt0FZ3LQ03/+/1+XQgw9oM3b+gkfyzKI/5Wsz2/4f7c479k2S7LbrwNZz3bp1y1sH9M/iJUsDsDXa0EAMHPjWHDDmk69IIZLkxRdfyosvvpQnn3w6jz3+VP74zEMZNXJ47rt/fgdUDHSkDksiNrbZRbkHHnjgFdtyb8zrWVsXXs3LLzenqlPbxrZTp05p2cj6Az+Zc2uG7rlHBu/x9jbnhw7ePd26dc0zi/7ezK5dty5/XrwkA+r6bZnCAf4JGxqI3XcflLEH/muWLXup4mc6/b/fleVJLPDm0WFJxIknnpjjjjsu8+fPz/7779/aMCxZsiTz5s3L9773vfzXf/1XR5XHm9SH3z8y37vimvSv7ZfdB+2Sx554Kj+49if5l3Fj2oxbtXp1fnHHL3PilFdOuO7Vs2c+eejBufjS/5u6fjtlQF1tLr/6R0mSMR+xwg7Q/nr27JHddx/U+vWgXQdm7733yrJlL2Xx4qW57trvZt99huXQf5mYzp07p7b2bwubLFu2PGvXrs1737NvRozYO/fc+2Beeml5dnv7rjnrzJPy1FPPpPE+KQRvQCZWV9ShS7xee+21ueCCCzJ//vysX78+yd/Wrx0+fHimT5+eT37yk6/rvpZ45fVavfqv+eb3fpB5dzdm2UvLs/NOfXPwAR/OpM/+W7p27do67vr/+VnOu/C7ueOmq7J9r56vuM/adevyjVmX56e33J7m5uYMGzo4p37pP7L723dpz2+HNxBLvPLP2O9D9Zl3249ecf6KH1yXmWd/Pb9/8v6Nfm7/0Yfnrrsb8853Ds4FX5+Zd71raHr27J7Fi5fm1l/cmXMaLsxzzzVt6fJ5g9qal3hd/dXPtNuzev6fH7TbszanrWKfiLVr1+aFF15Ikuy0005t/lh7XffTRABvMJoI4I1mq24ivvLpdntWz9OubLdnbU5bxY7VXbt2Tf/+/Tu6DAAAYBNsFU0EAABsNcyJqKjDVmcCAAC2TZIIAAAotw1vAtdeJBEAAEAhkggAAChnTkRFkggAAKAQSQQAAJQrmRNRiSQCAAAoRBIBAADlzImoSBIBAAAUIokAAIAyJftEVCSJAAAACpFEAABAOXMiKpJEAAAAhWgiAACAQrzOBAAA5bzOVJEkAgAAKEQSAQAA5UqWeK1EEgEAABQiiQAAgHLmRFQkiQAAAAqRRAAAQJmSJKIiSQQAAFCIJAIAAMpJIiqSRAAAAIVIIgAAoFyLfSIqkUQAAACFSCIAAKCcOREVSSIAAIBCJBEAAFBOElGRJAIAAChEEgEAAGVKJUlEJZIIAACgEEkEAACUMyeiIkkEAABQiCYCAAAoxOtMAABQzutMFUkiAACAQiQRAABQpiSJqEgSAQAAFCKJAACAcpKIiiQRAABAIZIIAAAo19LRBWz9JBEAAEAhkggAAChjdabKJBEAAEAhkggAACgniahIEgEAABQiiQAAgHJWZ6pIEgEAABQiiQAAgDJWZ6pMEgEAABSiiQAAgHIt7XgU9Oc//zmf/vSns+OOO6Z79+4ZNmxYHnroodbrpVIpZ5xxRvr375/u3btn9OjRefLJJ9vcY9myZTnyyCNTU1OTPn365Nhjj82qVasK1aGJAACAbcBLL72U97///enatWt+/vOf53e/+12+/vWvZ4cddmgdc/755+eiiy7KrFmzcv/996dnz54ZO3ZsXn755dYxRx55ZB599NHMnTs3c+bMyd13353jjjuuUC1VpVLpDffS19oXnu7oEgA2q+4DPtjRJQBsVuvW/LmjS3hVL034cLs9a4cf37nJY0899dTcc889+eUvf7nR66VSKQMGDMgJJ5yQE088MUmyYsWK1NbWZvbs2TniiCPy2GOPZejQoXnwwQczYsSIJMktt9ySgw8+OH/6058yYMCATapFEgEAAGVKLaV2O5qbm7Ny5co2R3Nz80bruummmzJixIh84hOfSL9+/bLvvvvme9/7Xuv1Z555Jk1NTRk9enTrud69e2fkyJFpbGxMkjQ2NqZPnz6tDUSSjB49Op06dcr999+/yT8jTQQAAHSQhoaG9O7du83R0NCw0bFPP/10Lrnkkuyxxx659dZbM2nSpHzxi1/MFVdckSRpampKktTW1rb5XG1tbeu1pqam9OvXr831Ll26pG/fvq1jNoUlXgEAoFw7bjY3Y8aMTJ8+vc256urqjY5taWnJiBEjcs455yRJ9t133zzyyCOZNWtWJk6cuMVrLSeJAACADlJdXZ2ampo2x6s1Ef3798/QoUPbnBsyZEgWLVqUJKmrq0uSLFmypM2YJUuWtF6rq6vL0qVL21xft25dli1b1jpmU2giAACgTKml/Y4i3v/+92fhwoVtzj3xxBPZZZddkiSDBg1KXV1d5s2b13p95cqVuf/++1NfX58kqa+vz/LlyzN//vzWMbfffntaWloycuTITa7F60wAALANmDZtWt73vvflnHPOySc/+ck88MAD+e53v5vvfve7SZKqqqocf/zx+cpXvpI99tgjgwYNyumnn54BAwbksMMOS/K35OLAAw/M5z73ucyaNStr167NlClTcsQRR2zyykyJJgIAANpqxzkRRbznPe/JDTfckBkzZmTmzJkZNGhQvvGNb+TII49sHXPyySdn9erVOe6447J8+fJ84AMfyC233JLtttuudcxVV12VKVOmZP/990+nTp0yYcKEXHTRRYVqsU8EwDbAPhHAG83WvE/Ei+P2a7dn7XjzXe32rM1JEgEAAGWKzlV4MzKxGgAAKEQSAQAA5SQRFUkiAACAQiQRAABQxpyIyiQRAABAIZIIAAAoI4moTBIBAAAUIokAAIAykojKJBEAAEAhkggAAChXquroCrZ6kggAAKAQTQQAAFCI15kAAKCMidWVSSIAAIBCJBEAAFCm1GJidSWSCAAAoBBJBAAAlDEnojJJBAAAUIgkAgAAypRsNleRJAIAAChEEgEAAGXMiahMEgEAABQiiQAAgDL2iahMEgEAABQiiQAAgDKlUkdXsPWTRAAAAIVIIgAAoIw5EZVJIgAAgEIkEQAAUEYSUZkkAgAAKEQTAQAAFOJ1JgAAKGOJ18okEQAAQCGSCAAAKGNidWWSCAAAoBBJBAAAlCmVJBGVSCIAAIBCJBEAAFCm1NLRFWz9JBEAAEAhkggAACjTYk5ERZIIAACgEEkEAACUsTpTZZIIAACgEEkEAACUsWN1ZZIIAACgEEkEAACUKZU6uoKtnyQCAAAoRBIBAABlzImo7HU3EWvWrMnSpUvT0tJ2X/CBAwf+00UBAABbr8JNxJNPPpljjjkm9957b5vzpVIpVVVVWb9+/WYrDgAA2psdqysr3EQcffTR6dKlS+bMmZP+/funqsoPGQAA3kwKNxELFizI/PnzM3jw4C1RDwAAsJUr3EQMHTo0L7zwwpaoBQAAOlzJ60wVbdISrytXrmw9zjvvvJx88sm588478+KLL7a5tnLlyi1dLwAA0ME2KYno06dPm7kPpVIp+++/f5sxJlYDAPBGYLO5yjapibjjjju2dB0AAMA2YpOaiP3226/13xctWpS3ve1tr1iVqVQq5dlnn9281QEAQDuzxGtlmzQnotygQYPy/PPPv+L8smXLMmjQoM1SFAAAsPUqvDrThrkP/2jVqlXZbrvtNktRAADQUazOVNkmNxHTp09PklRVVeX0009Pjx49Wq+tX78+999/f/bZZ5/NXiAAALB12eTXmX7zm9/kN7/5TUqlUh5++OHWr3/zm9/k8ccfz957753Zs2dvwVIBAGDLK5Xa7yjizDPPTFVVVZujfAPol19+OZMnT86OO+6YXr16ZcKECVmyZEmbeyxatCjjxo1Ljx490q9fv5x00klZt25d4Z/RJicRG1Zo+uxnP5sLL7wwNTU1hR8GAAC8fnvttVduu+221q+7dPn7n/PTpk3LzTffnOuvvz69e/fOlClTMn78+Nxzzz1J/vb20Lhx41JXV5d77703ixcvzmc+85l07do155xzTqE6Cs+JuPzyy4t+BAAAthlb8+pMXbp0SV1d3SvOr1ixIpdeemmuvvrqfPSjH03yt7/bhwwZkvvuuy+jRo3KL37xi/zud7/Lbbfdltra2uyzzz45++yzc8opp+TMM89Mt27dNr2OooVvKOrV3H777UVvCQAAb0rNzc1pbm5uc666ujrV1dUbHf/kk09mwIAB2W677VJfX5+GhoYMHDgw8+fPz9q1azN69OjWsYMHD87AgQPT2NiYUaNGpbGxMcOGDUttbW3rmLFjx2bSpEl59NFHs++++25y3YWbiL333rvN12vXrs2CBQvyyCOPZOLEiUVvt0W8a+gRHV0CwGa1R5+3dHQJAG8a7bk6U0NDQ84666w257785S/nzDPPfMXYkSNHZvbs2dlzzz2zePHinHXWWfngBz+YRx55JE1NTenWrVv69OnT5jO1tbVpampKkjQ1NbVpIDZc33CtiMJNxAUXXLDR82eeeWZWrVpV9HYAAPCmNWPGjNZVUDd4tRTioIMOav33d73rXRk5cmR22WWXXHfddenevfsWrfMfFd5s7tV8+tOfzmWXXba5bgcAAB2ipVTVbkd1dXVqamraHK/WRPyjPn365B3veEeeeuqp1NXVZc2aNVm+fHmbMUuWLGmdQ1FXV/eK1Zo2fL2xeRavZbM1EY2NjTabAwCAdrJq1ar8/ve/T//+/TN8+PB07do18+bNa72+cOHCLFq0KPX19UmS+vr6PPzww1m6dGnrmLlz56ampiZDhw4t9OzCrzONHz++zdelUimLFy/OQw89lNNPP73o7QAAYKtScPuGdnPiiSfmYx/7WHbZZZc899xz+fKXv5zOnTvnU5/6VHr37p1jjz0206dPT9++fVNTU5OpU6emvr4+o0aNSpKMGTMmQ4cOzVFHHZXzzz8/TU1NOe200zJ58uRNTj82KNxE9O7du83XnTp1yp577pmZM2dmzJgxRW8HAABsgj/96U/51Kc+lRdffDE777xzPvCBD+S+++7LzjvvnORvc5c7deqUCRMmpLm5OWPHjs3FF1/c+vnOnTtnzpw5mTRpUurr69OzZ89MnDgxM2fOLFxLVam06XvlrV+/Pvfcc0+GDRuWHXbYofDD2suQfu/t6BIAAHgNjy19oKNLeFX3DRhfedBmMuq5n7TbszanQnMiOnfunDFjxrxiwgYAALxRtOfE6m1V4YnV73znO/P0009viVoAAIBtQOEm4itf+UpOPPHEzJkzJ4sXL87KlSvbHAAAsC0rlara7dhWbfLE6pkzZ+aEE07IwQcfnCT5+Mc/nqqqv3/jpVIpVVVVWb9+/eavEgAA2GpschNx1lln5fOf/3zuuOOOLVkPAAB0qJaOLmAbsMlNxIZFnPbbb78tVgwAALD1K7RPRPnrSwAA8EZUir95KynURLzjHe+o2EgsW7bsnyoIAADYuhVqIs4666xX7FgNAABvJC2bvBXzm1ehJuKII45Iv379tlQtAADANmCTmwjzIQAAeDNoMSeiok3ebG7D6kwAAMCb2yYnES0tVswFAOCNz+pMlW1yEgEAAJAUnFgNAABvdN6/qUwSAQAAFCKJAACAMuZEVCaJAAAACpFEAABAGXMiKpNEAAAAhWgiAACAQrzOBAAAZbzOVJkkAgAAKEQSAQAAZSzxWpkkAgAAKEQSAQAAZVoEERVJIgAAgEIkEQAAUKbFnIiKJBEAAEAhkggAAChT6ugCtgGSCAAAoBBJBAAAlLFjdWWSCAAAoBBJBAAAlGmpsjpTJZIIAACgEEkEAACUsTpTZZIIAACgEEkEAACUsTpTZZIIAACgEE0EAABQiNeZAACgTIsVXiuSRAAAAIVIIgAAoExLRBGVSCIAAIBCJBEAAFDGZnOVSSIAAIBCJBEAAFDG6kyVSSIAAIBCJBEAAFCmpaML2AZIIgAAgEIkEQAAUMbqTJVJIgAAgEIkEQAAUMbqTJVJIgAAgEIkEQAAUMbqTJVJIgAAgEIkEQAAUEYSUZkkAgAAKEQSAQAAZUpWZ6pIEgEAABSiiQAAgG3Mueeem6qqqhx//PGt515++eVMnjw5O+64Y3r16pUJEyZkyZIlbT63aNGijBs3Lj169Ei/fv1y0kknZd26dYWfr4kAAIAyLe14vB4PPvhgvvOd7+Rd73pXm/PTpk3LT3/601x//fW566678txzz2X8+PGt19evX59x48ZlzZo1uffee3PFFVdk9uzZOeOMMwrXoIkAAIBtxKpVq3LkkUfme9/7XnbYYYfW8ytWrMill16a//7v/85HP/rRDB8+PJdffnnuvffe3HfffUmSX/ziF/nd736XK6+8Mvvss08OOuignH322fn2t7+dNWvWFKpDEwEAAGXaM4lobm7OypUr2xzNzc2vWtvkyZMzbty4jB49us35+fPnZ+3atW3ODx48OAMHDkxjY2OSpLGxMcOGDUttbW3rmLFjx2blypV59NFHC/2MNBEAANBBGhoa0rt37zZHQ0PDRsdec801+fWvf73R601NTenWrVv69OnT5nxtbW2amppax5Q3EBuub7hWhCVeAQCgTKkdnzVjxoxMnz69zbnq6upXjHv22WfzpS99KXPnzs12223XXuW9KkkEAAB0kOrq6tTU1LQ5NtZEzJ8/P0uXLs273/3udOnSJV26dMldd92Viy66KF26dEltbW3WrFmT5cuXt/nckiVLUldXlySpq6t7xWpNG77eMGZTaSIAAKBMS1X7HZtq//33z8MPP5wFCxa0HiNGjMiRRx7Z+u9du3bNvHnzWj+zcOHCLFq0KPX19UmS+vr6PPzww1m6dGnrmLlz56ampiZDhw4t9DPyOhMAAGzltt9++7zzne9sc65nz57ZcccdW88fe+yxmT59evr27ZuamppMnTo19fX1GTVqVJJkzJgxGTp0aI466qicf/75aWpqymmnnZbJkydvNP14LZoIAAAo83r3b+hoF1xwQTp16pQJEyakubk5Y8eOzcUXX9x6vXPnzpkzZ04mTZqU+vr69OzZMxMnTszMmTMLP6uqVCq159yRdjGk33s7ugQAAF7DY0sf6OgSXtUFAz/dbs+atujKdnvW5iSJAACAMttqEtGeTKwGAAAKkUQAAECZN9y7/luAJAIAAChEEgEAAGWK7N/wZiWJAAAACpFEAABAGaszVSaJAAAACtFEAAAAhXidCQAAyljitTJJBAAAUIgkAgAAyrTIIiqSRAAAAIVIIgAAoIwlXiuTRAAAAIVIIgAAoIwZEZVJIgAAgEIkEQAAUMaciMokEQAAQCGSCAAAKNNS1dEVbP0kEQAAQCGSCAAAKGPH6sokEQAAQCGSCAAAKCOHqEwSAQAAFCKJAACAMvaJqEwSAQAAFCKJAACAMlZnqkwSAQAAFKKJAAAACvE6EwAAlPEyU2WSCAAAoBBJBAAAlLHEa2WSCAAAoBBJBAAAlLHEa2WSCAAAoBBJBAAAlJFDVCaJAAAACpFEAABAGaszVSaJAAAACpFEAABAmZJZERVJIgAAgEIkEQAAUMaciMokEQAAQCGSCAAAKGPH6sokEQAAQCGSCAAAKCOHqEwSAQAAFKKJAAAACvE6EwAAlDGxujJJBAAAUIgmAsp87osTc92ts/PQ03fkV4/ekm9e8bXsutvANmO6VXfL6eeelMbH5+ahZ+7MhZedmx137rvR+/XZoXfuWPDTPLb0gWxf06s9vgWANvxeg+Ja2vHYVmkioMx73vfuXH3Z9TnioGNz7CenpmuXzrn0um+me4/tWsfMOHtaPjzmgzn+32fkM4d+Pv3qds5Fl5+30fud/Y3T8sTvnmqv8gFewe81YEvQRECZ4474Um689uY8tfDpLHz0ycz44swMeFv/7PWuIUmSXtv3zPh/+3jOO+Mbuf9XD+V3//t4/vOLM/Pu9+6dvYe/s829jjh6QmpqeuWyi6/qiG8FIInfa/B6lNrxn22VJgJew4aofsXyFUmSvfYekm7duqbx7gdaxzzz1B/z3LOLs8+IYa3ndnvHoHzhhGNz6pQz09KyLYeVwBuN32vA5qCJgFdRVVWVGWdPz/z7F+TJx59OkuzUb8esaV6Tv6xc1WbsC88vy079dkySdO3WNf/1na/ka2ddlMV/XtLudQO8Gr/XYNOYE1HZVt1EPPvssznmmGNec0xzc3NWrlzZ5mgpbcv/k7C1OOO8k7PH4LfnhONOK/S56adNztNPPJOf/uiWLVQZwOvj9xqwuWzVTcSyZctyxRVXvOaYhoaG9O7du83x4l8Xt1OFvFGd1nBi9jvgA5k4/gtZsnhp6/kXlr6YbtXdXrEiyU47980LS19Mkoz8wIiM/fj+efi5e/Pwc/fm8h9/O0ly7+O/yJSTP9d+3wRAGb/XYNOZE1FZh242d9NNN73m9aeffrriPWbMmJHp06e3Ofee3T76T9XFm9tpDSdm9MEfzsTDJuXPi55rc+3R3z6WNWvWZtSH3pO5c+5Ikuy628AMeFv/LHjo4STJl445JdttV936mXfuMzTnXHRGjvr4f2TRH/7Uft8IwP/j9xqwuXVoE3HYYYelqqoqpdKrd2FVVVWveY/q6upUV1e3OdepaqsOWNiKnXHeyRk3fmymfObErF7919b3gf+yclWaX27Oqr+szk+uvimnnnV8Vry0Mqv+sjqnNZyY3zz4v/nt/EeSJM/+4c9t7tmnb58kye+feOYV7xwDbGl+r0FxXoyvrEObiP79++fiiy/OoYceutHrCxYsyPDhw9u5Kt7MPvXZw5MkP/if77Q5P2PqWbnx2puTJA2nX5CWlpZceNm56datW+65877MPOX8dq8VYFP4vQZsCVWl14oBtrCPf/zj2WeffTJz5syNXv/tb3+bfffdt/BSckP6vXdzlAcAwBby2NIHKg/qIEftMr7dnvV///iTTR57ySWX5JJLLskf/vCHJMlee+2VM844IwcddFCS5OWXX84JJ5yQa665Js3NzRk7dmwuvvji1NbWtt5j0aJFmTRpUu6444706tUrEydOTENDQ7p0KZYtdOh7PyeddFLe9773ver13XffPXfccUc7VgQAAFunt771rTn33HMzf/78PPTQQ/noRz+aQw89NI8++miSZNq0afnpT3+a66+/PnfddVeee+65jB//94Zo/fr1GTduXNasWZN77703V1xxRWbPnp0zzjijcC0dmkRsKZIIAICt29acRHy6HZOIKwskERvTt2/ffO1rX8vhhx+enXfeOVdffXUOP/xvrzE+/vjjGTJkSBobGzNq1Kj8/Oc/zyGHHJLnnnuuNZ2YNWtWTjnllDz//PPp1q3bJj/XDGQAAOggG9vzrLm5ueLn1q9fn2uuuSarV69OfX195s+fn7Vr12b06NGtYwYPHpyBAwemsbExSdLY2Jhhw4a1eb1p7NixWblyZWuasak0EQAAUKYlpXY7NrbnWUNDw6vW9vDDD6dXr16prq7O5z//+dxwww0ZOnRompqa0q1bt/Tp06fN+Nra2jQ1NSVJmpqa2jQQG65vuFZEh67OBAAAb2Yb2/PsH7cvKLfnnntmwYIFWbFiRX70ox9l4sSJueuuu7Z0ma+giQAAgDLtuZP0xvY8ey3dunXL7rvvniQZPnx4HnzwwVx44YX513/916xZsybLly9vk0YsWbIkdXV1SZK6uro88EDbuShLlixpvVaE15kAAGAb1dLSkubm5gwfPjxdu3bNvHnzWq8tXLgwixYtSn19fZKkvr4+Dz/8cJYuXdo6Zu7cuampqcnQoUMLPVcSAQAA24AZM2bkoIMOysCBA/OXv/wlV199de68887ceuut6d27d4499thMnz49ffv2TU1NTaZOnZr6+vqMGjUqSTJmzJgMHTo0Rx11VM4///w0NTXltNNOy+TJkwulIYkmAgAA2ii2zXH7Wbp0aT7zmc9k8eLF6d27d971rnfl1ltvzQEHHJAkueCCC9KpU6dMmDChzWZzG3Tu3Dlz5szJpEmTUl9fn549e2bixImvuvHza7FPBAAA7W5r3ifiX3c5rN2ede0fb2y3Z21OkggAACjT0o4Tq7dVJlYDAACFSCIAAKBMey7xuq2SRAAAAIVIIgAAoMzWujrT1kQSAQAAFCKJAACAMm/AHRA2O0kEAABQiCQCAADK2CeiMkkEAABQiCQCAADKWJ2pMkkEAABQiCQCAADK2LG6MkkEAABQiCQCAADKWJ2pMkkEAABQiCYCAAAoxOtMAABQplTyOlMlkggAAKAQSQQAAJSx2VxlkggAAKAQSQQAAJSx2VxlkggAAKAQSQQAAJSx2VxlkggAAKAQSQQAAJSxT0RlkggAAKAQSQQAAJQxJ6IySQQAAFCIJAIAAMrYJ6IySQQAAFCIJAIAAMq0WJ2pIkkEAABQiCQCAADKyCEqk0QAAACFaCIAAIBCvM4EAABlbDZXmSQCAAAoRBIBAABlJBGVSSIAAIBCJBEAAFCmZLO5iiQRAABAIZIIAAAoY05EZZIIAACgEEkEAACUKUkiKpJEAAAAhUgiAACgjNWZKpNEAAAAhUgiAACgjNWZKpNEAAAAhUgiAACgjDkRlUkiAACAQiQRAABQxpyIyiQRAABAIZIIAAAoY8fqyiQRAABAIZoIAACgEK8zAQBAmRZLvFYkiQAAAAqRRAAAQBkTqyuTRAAAwDagoaEh73nPe7L99tunX79+Oeyww7Jw4cI2Y15++eVMnjw5O+64Y3r16pUJEyZkyZIlbcYsWrQo48aNS48ePdKvX7+cdNJJWbduXaFaNBEAAFCmpVRqt6OIu+66K5MnT859992XuXPnZu3atRkzZkxWr17dOmbatGn56U9/muuvvz533XVXnnvuuYwfP771+vr16zNu3LisWbMm9957b6644orMnj07Z5xxRqFaqkqlN97MkSH93tvRJQAA8BoeW/pAR5fwqtrzb8l/5ufw/PPPp1+/frnrrrvyoQ99KCtWrMjOO++cq6++OocffniS5PHHH8+QIUPS2NiYUaNG5ec//3kOOeSQPPfcc6mtrU2SzJo1K6ecckqef/75dOvWbZOeLYkAAIAypXb855+xYsWKJEnfvn2TJPPnz8/atWszevTo1jGDBw/OwIED09jYmCRpbGzMsGHDWhuIJBk7dmxWrlyZRx99dJOfbWI1AAB0kObm5jQ3N7c5V11dnerq6tf8XEtLS44//vi8//3vzzvf+c4kSVNTU7p165Y+ffq0GVtbW5umpqbWMeUNxIbrG65tKkkEAACUac85EQ0NDendu3ebo6GhoWKNkydPziOPPJJrrrmmHX4irySJAACADjJjxoxMnz69zblKKcSUKVMyZ86c3H333XnrW9/aer6uri5r1qzJ8uXL26QRS5YsSV1dXeuYBx5oOw9jw+pNG8ZsCkkEAACUac85EdXV1ampqWlzvFoTUSqVMmXKlNxwww25/fbbM2jQoDbXhw8fnq5du2bevHmt5xYuXJhFixalvr4+SVJfX5+HH344S5cubR0zd+7c1NTUZOjQoZv8M5JEAADANmDy5Mm5+uqr8z//8z/ZfvvtW+cw9O7dO927d0/v3r1z7LHHZvr06enbt29qamoyderU1NfXZ9SoUUmSMWPGZOjQoTnqqKNy/vnnp6mpKaeddlomT55cMQEpZ4lXAADa3da8xOtuO7273Z71+xd+vcljq6qqNnr+8ssvz9FHH53kb5vNnXDCCfnhD3+Y5ubmjB07NhdffHGbV5X++Mc/ZtKkSbnzzjvTs2fPTJw4Meeee266dNn0fEETAQBAu9NE/E2RJmJr4nUmAAAo88/u3/BmYGI1AABQiCQCAADKlEotHV3CVk8SAQAAFKKJAAAACvE6EwAAlGkxsboiSQQAAFCIJAIAAMq8AbdR2+wkEQAAQCGSCAAAKGNORGWSCAAAoBBJBAAAlDEnojJJBAAAUIgkAgAAyrRIIiqSRAAAAIVIIgAAoEzJ6kwVSSIAAIBCJBEAAFDG6kyVSSIAAIBCJBEAAFDGjtWVSSIAAIBCJBEAAFDGnIjKJBEAAEAhkggAAChjx+rKJBEAAEAhmggAAKAQrzMBAEAZE6srk0QAAACFSCIAAKCMzeYqk0QAAACFSCIAAKCMORGVSSIAAIBCJBEAAFDGZnOVSSIAAIBCJBEAAFCmZHWmiiQRAABAIZIIAAAoY05EZZIIAACgEEkEAACUsU9EZZIIAACgEEkEAACUsTpTZZIIAACgEEkEAACUMSeiMkkEAABQiCYCAAAoxOtMAABQxutMlUkiAACAQiQRAABQRg5RmSQCAAAopKrkpS94XZqbm9PQ0JAZM2akurq6o8sB+Kf5vQZsKk0EvE4rV65M7969s2LFitTU1HR0OQD/NL/XgE3ldSYAAKAQTQQAAFCIJgIAAChEEwGvU3V1db785S+bfAi8Yfi9BmwqE6sBAIBCJBEAAEAhmggAAKAQTQQAAFCIJgIAAChEEwGv07e//e3suuuu2W677TJy5Mg88MADHV0SwOty991352Mf+1gGDBiQqqqq3HjjjR1dErCV00TA63Dttddm+vTp+fKXv5xf//rX2XvvvTN27NgsXbq0o0sDKGz16tXZe++98+1vf7ujSwG2EZZ4hddh5MiRec973pNvfetbSZKWlpa87W1vy9SpU3Pqqad2cHUAr19VVVVuuOGGHHbYYR1dCrAVk0RAQWvWrMn8+fMzevTo1nOdOnXK6NGj09jY2IGVAQC0D00EFPTCCy9k/fr1qa2tbXO+trY2TU1NHVQVAED70UQAAACFaCKgoJ122imdO3fOkiVL2pxfsmRJ6urqOqgqAID2o4mAgrp165bhw4dn3rx5redaWloyb9681NfXd2BlAADto0tHFwDbounTp2fixIkZMWJE3vve9+Yb3/hGVq9enc9+9rMdXRpAYatWrcpTTz3V+vUzzzyTBQsWpG/fvhk4cGAHVgZsrSzxCq/Tt771rXzta19LU1NT9tlnn1x00UUZOXJkR5cFUNidd96Zj3zkI684P3HixMyePbv9CwK2epoIAACgEHMiAACAQjQRAABAIZoIAACgEE0EAABQiCYCAAAoRBMBAAAUookAAAAK0UQAbGWOPvroHHbYYa1ff/jDH87xxx/f7nXceeedqaqqyvLly9v92QBs3TQRAJvo6KOPTlVVVaqqqtKtW7fsvvvumTlzZtatW7dFn/uTn/wkZ5999iaN9Yc/AO2hS0cXALAtOfDAA3P55Zenubk5P/vZzzJ58uR07do1M2bMaDNuzZo16dat22Z5Zt++fTfLfQBgc5FEABRQXV2durq67LLLLpk0aVJGjx6dm266qfUVpK9+9asZMGBA9txzzyTJs88+m09+8pPp06dP+vbtm0MPPTR/+MMfWu+3fv36TJ8+PX369MmOO+6Yk08+OaVSqc0z//F1pubm5pxyyil529velurq6uy+++659NJL84c//CEf+chHkiQ77LBDqqqqcvTRRydJWlpa0tDQkEGDBqV79+7Ze++986Mf/ajNc372s5/lHe94R7p3756PfOQjbeoEgHKaCIB/Qvfu3bNmzZokybx587Jw4cLMnTs3c+bMydq1azN27Nhsv/32+eUvf5l77rknvXr1yoEHHtj6ma9//euZPXt2LrvssvzqV7/KsmXLcsMNN7zmMz/zmc/khz/8YS666KI89thj+c53vpNevXrlbW97W3784x8nSRYuXJjFixfnwgsvTJI0NDTkBz/4QWbNmpVHH30006ZNy6c//encddddSf7W7IwfPz4f+9jHsmDBgvz7v/97Tj311C31YwNgG+d1JoDXoVQqZd68ebn11lszderUPP/88+nZs2e+//3vt77GdOWVV6alpSXf//73U1VVlSS5/PLL06dPn9x5550ZM2ZMvvGNb2TGjBkZP358kmTWrFm59dZbX/W5TzzxRK677rrMnTs3o0ePTpK8/e1vb72+4dWnfv36pU+fPkn+llycc845ue2221JfX9/6mV/96lf5zne+k/322y+XXHJJdtttt3z9619Pkuy55555+OGHc955523GnxoAbxSaCIAC5syZk169emXt2rVpaWnJv/3bv+XMM8/M5MmTM2zYsDbzIH7729/mqaeeyvbbb9/mHi+//HJ+//vfZ8WKFVm8eHFGjhzZeq1Lly4ZMWLEK15p2mDBggXp3Llz9ttvv02u+amnnspf//rXHHDAAW3Or1mzJvvuu2+S5LHHHmtTR5LWhgMA/pEmAqCAj3zkI7nkkkvSrVu3DBgwIF26/P3XaM+ePduMXbVqVYYPH56rrrrqFffZeeedX9fzu3fvXvgzq1atSpLcfPPNectb3tLmWnV19euqA4A3N00EQAE9e/bM7rvvvklj3/3ud+faa69Nv379UlNTs9Ex/fv3z/33358PfehDSZJ169Zl/vz5efe7373R8cOGDUtLS0vuuuuu1teZym1IQtavX996bujQoamurs6iRYteNcEYMmRIbrrppjbn7rvvvsrfJABvSiZWA2whRx55ZHbaaacceuih+eUvf5lnnnkmd955Z774xS/mT3/6U5LkS1/6Us4999zceOONefzxx/OFL3zhNfd42HXXXTNx4sQcc8wxufHGG1vved111yVJdtlll1RVVWXOnDl5/vnns2rVqmy//fY58cQTM23atFxxxRX5/e9/n1//+tf55je/mSuuuCJJ8vnPfz5PPvlkTjrppCxcuDBXX311Zs+evaV/RABsozQRAFtIjx49cvfdd2fgwIEZP358hgwZkmOPPTYvv/xyazJxwgkn5KijjsrEiRNTX1+f7bffPv/yL//ymve95JJLcvjhh+cLX/hCBg8enM997nNZvXp1kuQtb3lLzjrrrJx66qmpra3NlClTkiRnn312Tj/99DQ0NGTIkCE58MADc/PNN2fQoEFJkoEDB+bHP/5xbrzxxuy9996ZNWtWzjnnnC340wFgW1ZVerXZewAAABshiQAAAArRRAAAAIVoIgAAgEI0EQAAQCGaCAAAoBBNBAAAUIgmAgAAKEQTAQAAFKKJAAAACtFEAAAAhWgiAACAQjQRAABAIf8/v8LSc9/pKgoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are going to use the ann a lot of times, we will do it in a function\n",
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(26, input_dim=26, activation='relu'),\n",
    "        keras.layers.Dense(15, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    # weights == -1 : means no This means no adjusting for class imbalances. Its a standard training process without any emphasis on certain classes.\n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        # else example: weights = {0: 1, 1: 10} we can give weights for the class less frequent in the dataset to adjust a little bit for imbalance\n",
    "        # in this case,The model is forced to give more attention to the minority class\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67543228 1.92505133]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',  # Strategy to compute class weights ('balanced' means the function will balance weights inversely proportional to class frequencies)\n",
    "    classes=np.unique(y_train),  # List or array of class labels in the target variable\n",
    "    y=y_train  # The target labels (the variable you're predicting)\n",
    ")\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6510 - loss: 0.6500\n",
      "Epoch 2/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5102\n",
      "Epoch 3/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5177\n",
      "Epoch 4/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.4856\n",
      "Epoch 5/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.4775\n",
      "Epoch 6/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.4760\n",
      "Epoch 7/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.4767\n",
      "Epoch 8/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.4758\n",
      "Epoch 9/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.4672\n",
      "Epoch 10/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.4696\n",
      "Epoch 11/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7523 - loss: 0.4699\n",
      "Epoch 12/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4598\n",
      "Epoch 13/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.4579\n",
      "Epoch 14/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.4691\n",
      "Epoch 15/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.4634\n",
      "Epoch 16/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4619\n",
      "Epoch 17/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.4643\n",
      "Epoch 18/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7673 - loss: 0.4493\n",
      "Epoch 19/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.4674\n",
      "Epoch 20/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7543 - loss: 0.4731\n",
      "Epoch 21/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.4553\n",
      "Epoch 22/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4493\n",
      "Epoch 23/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.4535\n",
      "Epoch 24/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.4431\n",
      "Epoch 25/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.4519\n",
      "Epoch 26/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7647 - loss: 0.4442\n",
      "Epoch 27/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.4497\n",
      "Epoch 28/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7768 - loss: 0.4446\n",
      "Epoch 29/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7638 - loss: 0.4589\n",
      "Epoch 30/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4427\n",
      "Epoch 31/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7776 - loss: 0.4404\n",
      "Epoch 32/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.4421\n",
      "Epoch 33/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7752 - loss: 0.4437\n",
      "Epoch 34/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7744 - loss: 0.4481\n",
      "Epoch 35/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4293\n",
      "Epoch 36/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.4433\n",
      "Epoch 37/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.4362\n",
      "Epoch 38/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.4434\n",
      "Epoch 39/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7754 - loss: 0.4365\n",
      "Epoch 40/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.4402\n",
      "Epoch 41/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7643 - loss: 0.4496\n",
      "Epoch 42/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.4442\n",
      "Epoch 43/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.4335\n",
      "Epoch 44/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.4266\n",
      "Epoch 45/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4389\n",
      "Epoch 46/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4333\n",
      "Epoch 47/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.4383\n",
      "Epoch 48/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4180\n",
      "Epoch 49/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4313\n",
      "Epoch 50/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4145\n",
      "Epoch 51/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7896 - loss: 0.4211\n",
      "Epoch 52/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4302\n",
      "Epoch 53/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.4173\n",
      "Epoch 54/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.4355\n",
      "Epoch 55/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.4246\n",
      "Epoch 56/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7780 - loss: 0.4358\n",
      "Epoch 57/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4313\n",
      "Epoch 58/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.4416\n",
      "Epoch 59/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.4128\n",
      "Epoch 60/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7771 - loss: 0.4272\n",
      "Epoch 61/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.4310\n",
      "Epoch 62/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7779 - loss: 0.4302\n",
      "Epoch 63/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.4081\n",
      "Epoch 64/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.4086\n",
      "Epoch 65/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.4195\n",
      "Epoch 66/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7829 - loss: 0.4114\n",
      "Epoch 67/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7830 - loss: 0.4243\n",
      "Epoch 68/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7849 - loss: 0.4310\n",
      "Epoch 69/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4272\n",
      "Epoch 70/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.4348\n",
      "Epoch 71/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7805 - loss: 0.4324\n",
      "Epoch 72/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7860 - loss: 0.4220\n",
      "Epoch 73/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4202\n",
      "Epoch 74/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4138\n",
      "Epoch 75/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.4260\n",
      "Epoch 76/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4116\n",
      "Epoch 77/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4015\n",
      "Epoch 78/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4151\n",
      "Epoch 79/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4094\n",
      "Epoch 80/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.4165\n",
      "Epoch 81/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7932 - loss: 0.4058\n",
      "Epoch 82/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.4114\n",
      "Epoch 83/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4024\n",
      "Epoch 84/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4088\n",
      "Epoch 85/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.4059\n",
      "Epoch 86/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7854 - loss: 0.4047\n",
      "Epoch 87/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.4090\n",
      "Epoch 88/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4174\n",
      "Epoch 89/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7865 - loss: 0.4083\n",
      "Epoch 90/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.4177\n",
      "Epoch 91/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4120\n",
      "Epoch 92/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4023\n",
      "Epoch 93/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7892 - loss: 0.4196\n",
      "Epoch 94/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.3989\n",
      "Epoch 95/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4087\n",
      "Epoch 96/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.4119\n",
      "Epoch 97/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4094\n",
      "Epoch 98/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.3931\n",
      "Epoch 99/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4063\n",
      "Epoch 100/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.4093\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5564\n",
      "[0.548748254776001, 0.7320539951324463]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79       999\n",
      "           1       0.53      0.74      0.62       408\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.70      0.73      0.71      1407\n",
      "weighted avg       0.77      0.73      0.74      1407\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(X_train, np.array(y_train), X_test, y_test, 'binary_crossentropy', {0: class_weights[0], 1: class_weights[1]})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataset is imbalanced (Churn Variable: 5163 for Yes and 1869 for No) which can explain the lower F1-Score for values predicted as 1.\n",
    "Above, we tried to handle imbalance by Cost-sensitive learning (This can be done by assigning a higher cost to misclassifying the minority class, which encourages the model to prioritize correctly classifying the minority class.) : we can see above that we had the f-score for the minority class became a little bit higher.\n",
    "\n",
    "We will try different techniques to handle oversampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Undersrampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count, for each variable we count the number of rows that contains a unique value (0 and 1)\n",
    "count_class_0, count_class_1 = df1.Churn.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df2[df2['Churn'] == 0]\n",
    "df_class_1 = df2[df2['Churn'] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "Churn\n",
      "0    1869\n",
      "1    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "# creating a new sample by selecting a sample from the majority class that is equal to the number of the minority class (can be done before splitting data into test and train)\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.Churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under.drop('Churn',axis='columns')\n",
    "y = df_test_under['Churn']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    1495\n",
       "1    1495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in training Data\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 0.6385\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5350\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7557 - loss: 0.5179\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.4988\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.4889\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.4984\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.4798\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4690\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.4900\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.4889\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.4752\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.4642\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.4732\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4708\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4722\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.4711\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7707 - loss: 0.4699\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.4556\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4668\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.4649\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.4682\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.4620\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7729 - loss: 0.4765\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.4638\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4483\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4426\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4610\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.4369\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.4577\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4632\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4451\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4444\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.4625\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4461\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4624\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.4274\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.4640\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4465\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4434\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4533\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.4362\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 0.4418\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4461\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.4417\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4413\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 0.4417\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4370\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.4354\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4244\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4319\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.4268\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4172\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4287\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4188\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4334\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4345\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4267\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4268\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4335\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.4210\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4169\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4392\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4200\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.4149\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4137\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4176\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4178\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4395\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.4233\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.4166\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4162\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4174\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.4240\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.4019\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4225\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4273\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4277\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4229\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4145\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4089\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4060\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.4209\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.4051\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4078\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4184\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4222\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4168\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8235 - loss: 0.4051\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.3963\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3986\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4170\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4213\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.3968\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.3982\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.3915\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4049\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.4006\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4109\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.4004\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.3927\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5478  \n",
      "[0.5294284820556641, 0.7540106773376465]\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       374\n",
      "           1       0.75      0.76      0.76       374\n",
      "\n",
      "    accuracy                           0.75       748\n",
      "   macro avg       0.75      0.75      0.75       748\n",
      "weighted avg       0.75      0.75      0.75       748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1-Score for 1 has augmented significantly. Despite the small decrease of F1-Score of 0 values, We have a more balanced classifier using undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5625, 27), (1407, 27))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test dataframes: IMPORTANT: we have to split before doing oversampling to avoid overfitting (since we are duplicating values)\n",
    "train_df_wajih, test_df_wajih = train_test_split(df2, test_size=0.2, random_state=15, stratify=df2['Churn'])\n",
    "train_df_wajih.shape,test_df_wajih.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4130, 1495)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Class count\n",
    "count_class_0_wajih, count_class_1_wajih = train_df_wajih.Churn.value_counts()\n",
    "count_class_0_wajih,count_class_1_wajih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "Churn\n",
      "0    4130\n",
      "1    4130\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataframes\n",
    "train_df_wajih, test_df_wajih = train_test_split(df2, test_size=0.2, random_state=15, stratify=df2['Churn'])\n",
    "\n",
    "# Class count\n",
    "count_class_0_wajih, count_class_1_wajih = train_df_wajih.Churn.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0_wajih = train_df_wajih[train_df_wajih['Churn'] == 0]\n",
    "df_class_1_wajih = train_df_wajih[train_df_wajih['Churn'] == 1]\n",
    "\n",
    "\n",
    "df_class_1_over = df_class_1_wajih.sample(count_class_0_wajih, replace=True)\n",
    "df_test_over = pd.concat([df_class_0_wajih, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_test_over.drop('Churn',axis='columns')\n",
    "X_test = test_df_wajih.drop('Churn',axis='columns')\n",
    "y_train = df_test_over['Churn']\n",
    "y_test = test_df_wajih['Churn']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6479 - loss: 0.6169\n",
      "Epoch 2/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 0.5020\n",
      "Epoch 3/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7625 - loss: 0.4840\n",
      "Epoch 4/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.4744\n",
      "Epoch 5/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.4652\n",
      "Epoch 6/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.4630\n",
      "Epoch 7/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.4583\n",
      "Epoch 8/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7805 - loss: 0.4587\n",
      "Epoch 9/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7800 - loss: 0.4538\n",
      "Epoch 10/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.4541\n",
      "Epoch 11/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.4466\n",
      "Epoch 12/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4420\n",
      "Epoch 13/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.4384\n",
      "Epoch 14/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.4317\n",
      "Epoch 15/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.4406\n",
      "Epoch 16/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.4322\n",
      "Epoch 17/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4305\n",
      "Epoch 18/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4338\n",
      "Epoch 19/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.4359\n",
      "Epoch 20/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4137\n",
      "Epoch 21/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4230\n",
      "Epoch 22/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4088\n",
      "Epoch 23/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4174\n",
      "Epoch 24/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4097\n",
      "Epoch 25/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4198\n",
      "Epoch 26/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4061\n",
      "Epoch 27/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4065\n",
      "Epoch 28/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4057\n",
      "Epoch 29/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8214 - loss: 0.3973\n",
      "Epoch 30/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4005\n",
      "Epoch 31/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8263 - loss: 0.3960\n",
      "Epoch 32/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4000\n",
      "Epoch 33/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.4040\n",
      "Epoch 34/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - loss: 0.3921\n",
      "Epoch 35/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3882\n",
      "Epoch 36/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3822\n",
      "Epoch 37/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.3887\n",
      "Epoch 38/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8194 - loss: 0.3939\n",
      "Epoch 39/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3932\n",
      "Epoch 40/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8239 - loss: 0.3834\n",
      "Epoch 41/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3896\n",
      "Epoch 42/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3873\n",
      "Epoch 43/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8272 - loss: 0.3796\n",
      "Epoch 44/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.3768\n",
      "Epoch 45/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.3830\n",
      "Epoch 46/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.3868\n",
      "Epoch 47/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8272 - loss: 0.3847\n",
      "Epoch 48/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8342 - loss: 0.3799\n",
      "Epoch 49/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3781\n",
      "Epoch 50/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8304 - loss: 0.3792\n",
      "Epoch 51/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8328 - loss: 0.3755\n",
      "Epoch 52/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3720\n",
      "Epoch 53/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3629\n",
      "Epoch 54/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.3768\n",
      "Epoch 55/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3644\n",
      "Epoch 56/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3591\n",
      "Epoch 57/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.3690\n",
      "Epoch 58/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3638\n",
      "Epoch 59/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.3688\n",
      "Epoch 60/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8472 - loss: 0.3572\n",
      "Epoch 61/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3596\n",
      "Epoch 62/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3621\n",
      "Epoch 63/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3710\n",
      "Epoch 64/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.3543\n",
      "Epoch 65/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3646\n",
      "Epoch 66/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3655\n",
      "Epoch 67/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8446 - loss: 0.3582\n",
      "Epoch 68/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3485\n",
      "Epoch 69/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.3524\n",
      "Epoch 70/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3496\n",
      "Epoch 71/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3397\n",
      "Epoch 72/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.3486\n",
      "Epoch 73/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3559\n",
      "Epoch 74/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.3508\n",
      "Epoch 75/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.3574\n",
      "Epoch 76/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3591\n",
      "Epoch 77/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3519\n",
      "Epoch 78/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3478\n",
      "Epoch 79/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3475\n",
      "Epoch 80/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3510\n",
      "Epoch 81/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3478\n",
      "Epoch 82/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.3454\n",
      "Epoch 83/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3620\n",
      "Epoch 84/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3508\n",
      "Epoch 85/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8502 - loss: 0.3421\n",
      "Epoch 86/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3398\n",
      "Epoch 87/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3549\n",
      "Epoch 88/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3400\n",
      "Epoch 89/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3458\n",
      "Epoch 90/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.3338\n",
      "Epoch 91/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8505 - loss: 0.3432\n",
      "Epoch 92/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3367\n",
      "Epoch 93/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3406\n",
      "Epoch 94/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.3447\n",
      "Epoch 95/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3415\n",
      "Epoch 96/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8522 - loss: 0.3392\n",
      "Epoch 97/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8489 - loss: 0.3457\n",
      "Epoch 98/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3374\n",
      "Epoch 99/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3381\n",
      "Epoch 100/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3422\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.5836\n",
      "[0.6122759580612183, 0.732764720916748]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      1033\n",
      "           1       0.50      0.66      0.57       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.68      0.71      0.69      1407\n",
      "weighted avg       0.76      0.73      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = -1\n",
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampling did not yield to a better results: a slight increase in the F1-score for 1 value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - SMOTE: Synthetic Minority Oversampling Technique: Generate synthetic samples: Create synthetic data points by interpolating between the chosen sample and its neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn\n",
      "0    4130\n",
      "1    4130\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the features and target\n",
    "X = df2.drop('Churn', axis='columns')\n",
    "y = df2['Churn']\n",
    "\n",
    "# Split the data into train and test sets first (before applying SMOTE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "# Apply SMOTE only on the training data\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new value counts of the target variable in the resampled training data\n",
    "print(y_train_sm.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5657\n",
      "Epoch 2/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7867 - loss: 0.4515\n",
      "Epoch 3/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7887 - loss: 0.4529\n",
      "Epoch 4/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7931 - loss: 0.4463\n",
      "Epoch 5/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7970 - loss: 0.4439\n",
      "Epoch 6/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4374\n",
      "Epoch 7/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.4380\n",
      "Epoch 8/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4247\n",
      "Epoch 9/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.4194\n",
      "Epoch 10/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8137 - loss: 0.4154\n",
      "Epoch 11/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.4190\n",
      "Epoch 12/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4156\n",
      "Epoch 13/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4159\n",
      "Epoch 14/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8142 - loss: 0.4112\n",
      "Epoch 15/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.3997\n",
      "Epoch 16/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8166 - loss: 0.4037\n",
      "Epoch 17/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8216 - loss: 0.4012\n",
      "Epoch 18/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.3960\n",
      "Epoch 19/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.3887\n",
      "Epoch 20/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8240 - loss: 0.3927\n",
      "Epoch 21/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3882\n",
      "Epoch 22/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8240 - loss: 0.3829\n",
      "Epoch 23/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.3790\n",
      "Epoch 24/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 0.3839\n",
      "Epoch 25/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.3764\n",
      "Epoch 26/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3791\n",
      "Epoch 27/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3764\n",
      "Epoch 28/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3714\n",
      "Epoch 29/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3683\n",
      "Epoch 30/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3711\n",
      "Epoch 31/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3833\n",
      "Epoch 32/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.3714\n",
      "Epoch 33/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3650\n",
      "Epoch 34/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3670\n",
      "Epoch 35/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3644\n",
      "Epoch 36/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3628\n",
      "Epoch 37/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3540\n",
      "Epoch 38/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3598\n",
      "Epoch 39/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3549\n",
      "Epoch 40/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3563\n",
      "Epoch 41/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3642\n",
      "Epoch 42/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3562\n",
      "Epoch 43/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3525\n",
      "Epoch 44/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3532\n",
      "Epoch 45/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3558\n",
      "Epoch 46/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3500\n",
      "Epoch 47/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8455 - loss: 0.3514\n",
      "Epoch 48/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3479\n",
      "Epoch 49/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3667\n",
      "Epoch 50/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8487 - loss: 0.3434\n",
      "Epoch 51/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3474\n",
      "Epoch 52/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3513\n",
      "Epoch 53/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3421\n",
      "Epoch 54/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3429\n",
      "Epoch 55/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3392\n",
      "Epoch 56/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3426\n",
      "Epoch 57/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3498\n",
      "Epoch 58/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3439\n",
      "Epoch 59/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3422\n",
      "Epoch 60/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3457\n",
      "Epoch 61/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.3387\n",
      "Epoch 62/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3371\n",
      "Epoch 63/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 0.3396\n",
      "Epoch 64/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8514 - loss: 0.3471\n",
      "Epoch 65/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.3419\n",
      "Epoch 66/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.3345\n",
      "Epoch 67/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3348\n",
      "Epoch 68/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8440 - loss: 0.3461\n",
      "Epoch 69/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3313\n",
      "Epoch 70/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3544\n",
      "Epoch 71/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3363\n",
      "Epoch 72/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8517 - loss: 0.3299\n",
      "Epoch 73/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.3381\n",
      "Epoch 74/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.3337\n",
      "Epoch 75/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8514 - loss: 0.3310\n",
      "Epoch 76/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3323\n",
      "Epoch 77/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.3165\n",
      "Epoch 78/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3374\n",
      "Epoch 79/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3348\n",
      "Epoch 80/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3249\n",
      "Epoch 81/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3283\n",
      "Epoch 82/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.3349\n",
      "Epoch 83/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.3166\n",
      "Epoch 84/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3269\n",
      "Epoch 85/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3222\n",
      "Epoch 86/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8537 - loss: 0.3367\n",
      "Epoch 87/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.3344\n",
      "Epoch 88/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3292\n",
      "Epoch 89/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3319\n",
      "Epoch 90/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3321\n",
      "Epoch 91/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3312\n",
      "Epoch 92/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3227\n",
      "Epoch 93/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.3266\n",
      "Epoch 94/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 0.3325\n",
      "Epoch 95/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3182\n",
      "Epoch 96/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3151\n",
      "Epoch 97/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8573 - loss: 0.3258\n",
      "Epoch 98/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3253\n",
      "Epoch 99/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3117\n",
      "Epoch 100/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3192\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.5216\n",
      "[0.5464333295822144, 0.759772539138794]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1033\n",
      "           1       0.54      0.64      0.58       374\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.72      0.71      1407\n",
      "weighted avg       0.77      0.76      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train_sm, y_train_sm, X_test, y_test, 'binary_crossentropy', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE technique did not yield a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Method: we will the model 3 times, each time with a number of rows that is balanced with the number of rows of the minority and then we combine the 3 models and predict as a voting majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regain Original features and labels\n",
    "X = df2.drop('Churn',axis='columns')\n",
    "y = df2['Churn']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "df3 = X_train.copy()\n",
    "df3['Churn'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class0 = df3[df3.Churn==0]\n",
    "df3_class1 = df3[df3.Churn==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    # start:end to select the rows that will be used from the majority class\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Churn', axis='columns')\n",
    "    y_train = df_train.Churn\n",
    "    return X_train, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 0.6684\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5295\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.4925\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.5081\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4862\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7692 - loss: 0.4791\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4825\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 0.4927\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4694\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.4844\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.4897\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.4676\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4688\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.4722\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4707\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7772 - loss: 0.4648\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.4714\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.4588\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4680\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4639\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4560\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.4551\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4588\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.4562\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8014 - loss: 0.4446\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.4571\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4390\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4631\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.4600\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.4644\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4504\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.4433\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4477\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4461\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.4522\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.4416\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4427\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4348\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.4392\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4382\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.4411\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.4266\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.4379\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4330\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4444\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4312\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.4389\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.4215\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4340\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4263\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.4442\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4255\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4282\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4186\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4119\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4209\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.3988\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4117\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.4149\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.4158\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.4114\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.4263\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4083\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4010\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4196\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4012\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4177\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.4026\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.3948\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4173\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4001\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3848\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4023\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.3958\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.3980\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4050\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4085\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4019\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.3975\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.3888\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.3920\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.3891\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4062\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4043\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3860\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.3858\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.3827\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.3954\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.3954\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.3876\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.3808\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8235 - loss: 0.3962\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4079\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3732\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.4084\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4022\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.3847\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.3776\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3913\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.3848\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.5293\n",
      "[0.5534383654594421, 0.7356076836585999]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      1033\n",
      "           1       0.50      0.73      0.60       374\n",
      "\n",
      "    accuracy                           0.74      1407\n",
      "   macro avg       0.69      0.73      0.70      1407\n",
      "weighted avg       0.78      0.74      0.75      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 0, 1495)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6355 - loss: 0.6468\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7526 - loss: 0.5178\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.4897\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.4855\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.4899\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.4837\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.4896\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.4860\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7707 - loss: 0.4767\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.4796\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4676\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.4765\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.4672\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.4871\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4679\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.4667\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.4780\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.4689\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.4720\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.4649\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7771 - loss: 0.4561\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4683\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4640\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.4525\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.4488\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4571\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4494\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4571\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.4555\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4292\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.4499\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4447\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4423\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7729 - loss: 0.4480\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.4590\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.4514\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4329\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.4388\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.4499\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4421\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.4287\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 0.4422\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4313\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.4432\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4173\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4250\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4321\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.4309\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4184\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7935 - loss: 0.4423\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4110\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4153\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.4164\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.4212\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8014 - loss: 0.4235\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.4369\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.4263\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4182\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.4057\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.4148\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4036\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4047\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4153\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4016\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.3988\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.4216\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.4072\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4019\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4037\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4026\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4042\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4049\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4138\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.4180\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4032\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4090\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4178\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.3967\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.3849\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4061\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.3971\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.3858\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.3821\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4045\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.3838\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.3831\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.3946\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.3918\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.3946\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.3818\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.3872\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.3809\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.3831\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.3870\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.3825\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3735\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.3834\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.3779\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3654\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.3874\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7402 - loss: 0.5203\n",
      "[0.5597341656684875, 0.713575005531311]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78      1033\n",
      "           1       0.47      0.72      0.57       374\n",
      "\n",
      "    accuracy                           0.71      1407\n",
      "   macro avg       0.67      0.72      0.68      1407\n",
      "weighted avg       0.77      0.71      0.73      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 1495, 2990)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wajih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5411 - loss: 0.6842\n",
      "Epoch 2/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.5204\n",
      "Epoch 3/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.5038\n",
      "Epoch 4/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.4803\n",
      "Epoch 5/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.4802\n",
      "Epoch 6/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.4679\n",
      "Epoch 7/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4688\n",
      "Epoch 8/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4663\n",
      "Epoch 9/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.4581\n",
      "Epoch 10/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.4755\n",
      "Epoch 11/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4669\n",
      "Epoch 12/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4607\n",
      "Epoch 13/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4508\n",
      "Epoch 14/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4279\n",
      "Epoch 15/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.4523\n",
      "Epoch 16/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7799 - loss: 0.4662\n",
      "Epoch 17/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4609\n",
      "Epoch 18/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4309\n",
      "Epoch 19/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4251\n",
      "Epoch 20/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4640\n",
      "Epoch 21/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4487\n",
      "Epoch 22/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4284\n",
      "Epoch 23/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4528\n",
      "Epoch 24/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.4332\n",
      "Epoch 25/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.4453\n",
      "Epoch 26/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4234\n",
      "Epoch 27/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4252\n",
      "Epoch 28/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4226\n",
      "Epoch 29/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.4442\n",
      "Epoch 30/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.4285\n",
      "Epoch 31/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.4421\n",
      "Epoch 32/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4170\n",
      "Epoch 33/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4494\n",
      "Epoch 34/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7926 - loss: 0.4418\n",
      "Epoch 35/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4281\n",
      "Epoch 36/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4260\n",
      "Epoch 37/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.4299\n",
      "Epoch 38/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4405\n",
      "Epoch 39/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.4423\n",
      "Epoch 40/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4120\n",
      "Epoch 41/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4306\n",
      "Epoch 42/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4139\n",
      "Epoch 43/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.4058\n",
      "Epoch 44/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4150\n",
      "Epoch 45/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4159\n",
      "Epoch 46/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4276\n",
      "Epoch 47/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4079\n",
      "Epoch 48/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.3958\n",
      "Epoch 49/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4225\n",
      "Epoch 50/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.4240\n",
      "Epoch 51/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4064\n",
      "Epoch 52/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4158\n",
      "Epoch 53/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.4144\n",
      "Epoch 54/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.3985\n",
      "Epoch 55/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3908\n",
      "Epoch 56/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.4124\n",
      "Epoch 57/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4072\n",
      "Epoch 58/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.4091\n",
      "Epoch 59/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4045\n",
      "Epoch 60/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.3922\n",
      "Epoch 61/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.3915\n",
      "Epoch 62/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3988\n",
      "Epoch 63/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.3933\n",
      "Epoch 64/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4017\n",
      "Epoch 65/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.3931\n",
      "Epoch 66/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4158\n",
      "Epoch 67/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3962\n",
      "Epoch 68/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4053\n",
      "Epoch 69/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3892\n",
      "Epoch 70/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.3890\n",
      "Epoch 71/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.3854\n",
      "Epoch 72/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.3993\n",
      "Epoch 73/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4076\n",
      "Epoch 74/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.3891\n",
      "Epoch 75/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4056\n",
      "Epoch 76/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3819\n",
      "Epoch 77/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.3944\n",
      "Epoch 78/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4001\n",
      "Epoch 79/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.3987\n",
      "Epoch 80/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.3953\n",
      "Epoch 81/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.3889\n",
      "Epoch 82/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.3996\n",
      "Epoch 83/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.3944\n",
      "Epoch 84/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3624\n",
      "Epoch 85/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3876\n",
      "Epoch 86/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.3943\n",
      "Epoch 87/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3853\n",
      "Epoch 88/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3767\n",
      "Epoch 89/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3837\n",
      "Epoch 90/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3768\n",
      "Epoch 91/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.3848\n",
      "Epoch 92/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.3734\n",
      "Epoch 93/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.3988\n",
      "Epoch 94/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.3738\n",
      "Epoch 95/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.3861\n",
      "Epoch 96/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.3876\n",
      "Epoch 97/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3666\n",
      "Epoch 98/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3632\n",
      "Epoch 99/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3883\n",
      "Epoch 100/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3708\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.6374\n",
      "[0.6451678276062012, 0.6837242245674133]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.65      0.75      1033\n",
      "           1       0.45      0.79      0.57       374\n",
      "\n",
      "    accuracy                           0.68      1407\n",
      "   macro avg       0.67      0.72      0.66      1407\n",
      "weighted avg       0.78      0.68      0.70      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 2990, 4130)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1033\n",
      "           1       0.48      0.76      0.59       374\n",
      "\n",
      "    accuracy                           0.72      1407\n",
      "   macro avg       0.69      0.73      0.69      1407\n",
      "weighted avg       0.78      0.72      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly better performance using the ensemble technique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
